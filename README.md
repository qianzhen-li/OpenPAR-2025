# ğŸŒŸ OpenPAR: The Ultimate Collection (2022-2025)

æœ¬é¡¹ç›®æ—¨åœ¨å»ºç«‹ä¸€ä¸ª **Pedestrian Attribute Recognition (PAR)** é¢†åŸŸçš„å…¨æ™¯çŸ¥è¯†åº“ã€‚
æ ¸å¿ƒå†…å®¹åŸºäº **Event-AHU (å®‰å¾½å¤§å­¦)** å›¢é˜Ÿçš„å¼€æºæˆæœï¼ŒåŒæ—¶æ”¶å½•äº† **CVPR / AAAI / TPAMI** ç­‰é¡¶çº§ä¼šè®®çš„ SOTA å·¥ä½œã€‚

> **ğŸš€ Core Framework**: [https://github.com/Event-AHU/OpenPAR](https://github.com/Event-AHU/OpenPAR)

---

## ğŸ—ºï¸ Roadmap & Relationships (æŠ€æœ¯æ¼”è¿›å›¾è°±)

æŠ€æœ¯æ˜¯å¦‚ä½•ä» 2022 æ¼”å˜åˆ° 2025 çš„ï¼Ÿè¯·çœ‹ä¸‹å›¾ï¼š

```mermaid
graph TD
    subgraph Phase1 ["Phase 1: Foundations (2022-2023)"]
        A["Relation Modeling<br>GCN (AAAI 2022)"]
        B["Vision Transformer<br>ViT Baseline"]
    end

    subgraph Phase2 ["Phase 2: Semantic Expansion (2023-2024)"]
        B --> C["CLIP-Prompt Fusion<br>TCSVT 2024 (Prompt Tuning)"]
        C --> C1["Video Side-Tuning<br>TCSVT 2024 (Efficiency)"]
        C --> C2["Unsupervised GAAP<br>IJCAI 2024 (Pseudo Label)"]
    end

    subgraph Phase3 ["Phase 3: New Era (2025)"]
        B --> D["Mamba & RWKV<br>T-MM 2024 (Linear Complexity)"]
        D --> D1["RGB-Event Fusion<br>ArXiv 2025 (Multi-Modal)"]
        
        C --> E["LLM Agent<br>AAAI 2025 (MSP60K Dataset)"]
        
        A --> F["HyperGraph<br>ArXiv 2025 (Structure Learning)"]
    end
    
    style D fill:#f9f,stroke:#333,stroke-width:2px
    style E fill:#bbf,stroke:#333,stroke-width:2px
    style D1 fill:#f96,stroke:#333,stroke-width:2px


## ğŸ“š ç»å…¸èµ„æºå›æº¯ (Before 2022)
å¦‚æœä½ éœ€è¦æŸ¥æ‰¾ 2022 å¹´ä»¥å‰çš„ç»å…¸ Baselineï¼Œè¯·å‚è€ƒï¼š
* [Older Works Collection 1](https://github.com/wangxiao5791509/Pedestrian-Attribute-Recognition-Paper-List)
## ğŸ¤ å¦‚ä½•è´¡çŒ®
1. åœ¨ `papers` æ–‡ä»¶å¤¹ä¸­æ·»åŠ  PDFï¼ˆå¯é€‰ï¼‰ã€‚
2. åœ¨ `README.md` è¡¨æ ¼ä¸­è¿½åŠ æ–°è®ºæ–‡ã€‚
3. å¦‚æœå¤ç°äº†ä»£ç ï¼Œè¯·é“¾æ¥åˆ° `code/` ç›®å½•ã€‚
