# ğŸŒŸ OpenPAR: The Ultimate Collection (2022-2025)

æœ¬é¡¹ç›®æ—¨åœ¨å»ºç«‹ä¸€ä¸ª **Pedestrian Attribute Recognition (PAR)** é¢†åŸŸçš„å…¨æ™¯çŸ¥è¯†åº“ã€‚
æ ¸å¿ƒå†…å®¹åŸºäº **Event-AHU (å®‰å¾½å¤§å­¦)** å›¢é˜Ÿçš„å¼€æºæˆæœï¼ŒåŒæ—¶æ”¶å½•äº† **CVPR / AAAI / TPAMI** ç­‰é¡¶çº§ä¼šè®®çš„ SOTA å·¥ä½œã€‚

> **ğŸš€ Core Framework**: [https://github.com/Event-AHU/OpenPAR](https://github.com/Event-AHU/OpenPAR)

---

## ğŸ—ºï¸ Technical Roadmap (æŠ€æœ¯æ¼”è¿›è·¯çº¿)

æœ¬é¡¹ç›®è®°å½•äº† PAR é¢†åŸŸä» 2022 åˆ° 2025 å¹´çš„ä¸‰å¤§æŠ€æœ¯æ¼”è¿›é˜¶æ®µï¼š

### **Phase 1: åŸºç¡€å¥ åŸºæœŸ (2022-2023)**
* **æ ¸å¿ƒä»»åŠ¡**: å»ºç«‹å¼º Baselineï¼ŒæŒ–æ˜å±æ€§é—´çš„é€»è¾‘å…³ç³»ã€‚
* **ä»£è¡¨æŠ€æœ¯**:
    * **GCN (å›¾å·ç§¯)**: åˆ©ç”¨å›¾ç½‘ç»œç¡¬ç¼–ç å±æ€§å…±ç°å…³ç³»ï¼ˆå¦‚ï¼šé•¿å‘ $\rightarrow$ å¥³æ€§ï¼‰ã€‚
    * **ViT (Vision Transformer)**: ç¡®ç«‹äº† Transformer åœ¨ PAR ä¸­çš„ç»Ÿæ²»åœ°ä½ï¼Œå–ä»£ CNNã€‚

### **Phase 2: è¯­ä¹‰å¢å¼ºæœŸ (2023-2024)**
* **æ ¸å¿ƒç—›ç‚¹**: çº¯è§†è§‰æ¨¡å‹ç¼ºä¹è¯­ä¹‰ç†è§£ï¼Œä¸”è§†é¢‘æ¨¡å‹æ˜¾å­˜å ç”¨è¿‡é«˜ã€‚
* **æŠ€æœ¯çªç ´**:
    * **CLIP + Prompt**: å¼•å…¥â€œæç¤ºå­¦ä¹ â€ï¼Œå°†å±æ€§åˆ—è¡¨è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€å¥å­ï¼Œåˆ©ç”¨ CLIP çš„çŸ¥è¯†åº“æå‡æ³›åŒ–æ€§ã€‚
    * **Side-Tuning**: é’ˆå¯¹è§†é¢‘ PARï¼Œå¼€å‘äº†â€œä¾§è¾¹å¾®è°ƒâ€æŠ€æœ¯ï¼Œå†»ç»“å¤§æ¨¡å‹ï¼Œåªè®­ç»ƒè½»é‡çº§æ—¶åºæ¨¡å—ã€‚

### **Phase 3: æ–°èŒƒå¼çˆ†å‘æœŸ (2025 - Present)**
* **æ ¸å¿ƒè¶‹åŠ¿**: è¿½æ±‚æè‡´æ•ˆç‡ï¼ˆçº¿æ€§å¤æ‚åº¦ï¼‰ä¸è§£å†³æç«¯åœºæ™¯ï¼ˆå¤œé—´/é®æŒ¡ï¼‰ã€‚
* **å‰æ²¿æ–¹å‘**:
    * **Mamba & RWKV**: æŠ›å¼ƒ Transformerï¼Œä½¿ç”¨çº¿æ€§å¤æ‚åº¦çš„ SSM æ¶æ„ï¼Œæ¨ç†é€Ÿåº¦å¤§å¹…æå‡ã€‚
    * **RGB-Event**: é¦–æ¬¡å¼•å…¥äº‹ä»¶ç›¸æœºï¼Œåˆ©ç”¨é«˜é¢‘è„‰å†²è§£å†³å¤œé—´ä½å…‰å’Œè¿åŠ¨æ¨¡ç³Šé—®é¢˜ã€‚
    * **LLM Agent**: åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ¸…æ´—æ•°æ®ï¼ˆMSP60Kï¼‰å¹¶å¢å¼ºè¯­ä¹‰æ¨ç†ã€‚
    * **HyperGraph**: åˆ©ç”¨è¶…å›¾å»ºæ¨¡å¤šéƒ¨ä½é®æŒ¡å…³ç³»ã€‚

---

## ğŸ”¥ Part 1: Event-AHU Core Works (2024-2025)
*åŸºäº OpenPAR æ¡†æ¶çš„æœ€æ–°å‰æ²¿è¿›å±•ï¼Œæ¶µç›– Mambaã€RWKVã€LLM åŠå¤æ‚åœºæ™¯ã€‚*

### 1. New Architectures (Mamba / RWKV / SNN)
> **è¶‹åŠ¿è§£è¯»**: æŠ›å¼ƒæ²‰é‡çš„ Transformerï¼Œè½¬å‘çº¿æ€§å¤æ‚åº¦çš„ Mamba å’Œ RWKVï¼Œè¿½æ±‚æè‡´çš„æ¨ç†æ•ˆç‡ã€‚

| Paper Title & Venue | Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **RGB-Event based PAR: Benchmark & Asymmetric RWKV Fusion**<br>(ArXiv 2025) [\[PDF\]](https://arxiv.org/abs/2504.10018) | [Link](https://github.com/Event-AHU/OpenPAR) | **(æœ€æ–°)** é¦–æ¬¡å¼•å…¥äº‹ä»¶ç›¸æœºè§£å†³å¤œé—´/è¿åŠ¨æ¨¡ç³Šéš¾é¢˜ã€‚**äº®ç‚¹**ï¼šè®¾è®¡äº†â€œéå¯¹ç§° RWKVâ€æ¶æ„ï¼Œä¸“é—¨å¤„ç†é«˜é¢‘ç¨€ç–çš„äº‹ä»¶æµæ•°æ®ï¼Œæ¯”çº¯ RGB æ–¹æ³•åœ¨å¤œé—´æå‡æ˜¾è‘—ã€‚ |
| **An Empirical Study of Mamba-based PAR**<br>(IEEE T-MM 2024) [\[PDF\]](https://arxiv.org/abs/2407.10374) | [Link](https://github.com/Event-AHU/OpenPAR) | **(åŸºå‡†)** PAR é¢†åŸŸé¦–ç¯‡ Mamba è¯„æµ‹ã€‚**é¿å‘**ï¼šå®éªŒå‘ç°ç›´æ¥å°†å±æ€§æ ‡ç­¾ä½œä¸º Token æ‹¼æ¥åˆ° VMamba ä¸­å¹¶ä¸èƒ½æå‡æ€§èƒ½ï¼Œè¿™æ‰“ç ´äº† ViT æ—¶ä»£çš„ç»éªŒä¸»ä¹‰ã€‚ |
| **SNN-PAR: Spiking Neural Networks for PAR**<br>(ICIG 2025) [\[PDF\]](https://arxiv.org/abs/2410.07857) | [Link](https://github.com/Event-AHU/OpenPAR) | **(ä½åŠŸè€—)** æ¢ç´¢è„‰å†²ç¥ç»ç½‘ç»œ (SNN) åœ¨ PAR ä¸­çš„åº”ç”¨ã€‚é€‚åˆéƒ¨ç½²åœ¨å¯¹åŠŸè€—æå…¶æ•æ„Ÿçš„è¾¹ç¼˜ç›‘æ§è®¾å¤‡ä¸Šã€‚ |

### 2. LLM & Vision-Language (Prompt / CLIP)
> **è¶‹åŠ¿è§£è¯»**: åˆ©ç”¨å¤§æ¨¡å‹ (LLM) çš„çŸ¥è¯†åº“æ¥å¼¥è¡¥è§†è§‰ç‰¹å¾çš„ä¸è¶³ï¼Œè§£å†³â€œé•¿å°¾å±æ€§â€å’Œâ€œè¯­ä¹‰ç†è§£â€é—®é¢˜ã€‚

| Paper Title & Venue | Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **PAR: A New Benchmark Dataset (MSP60K) & LLM Augmented Framework**<br>(AAAI 2025) [\[PDF\]](https://arxiv.org/abs/2408.09720) | [Link](https://github.com/Event-AHU/OpenPAR) | **(é‡ç£…æ•°æ®)** å‘å¸ƒäº† MSP60K (6ä¸‡å¼ å›¾)ï¼Œæ˜¯ PA100K ä¹‹åæœ€å¤§çš„æ–°åŸºå‡†ã€‚**äº®ç‚¹**ï¼šä¸ä»…ç”¨ LLM å¢å¼ºè®­ç»ƒï¼Œè¿˜ç”¨ LLM æ¸…æ´—äº†æ•°æ®æ ‡ç­¾ï¼Œè§£å†³äº†æ—§æ•°æ®é›†æ ‡æ³¨æ··ä¹±çš„é—®é¢˜ã€‚ |
| **Pedestrian Attribute Recognition via CLIP based Prompt Vision-Language Fusion**<br>(IEEE TCSVT 2024) [\[PDF\]](https://arxiv.org/abs/2312.10692) | [Link](https://github.com/Event-AHU/OpenPAR) | **(ç»å…¸)** Prompt Tuning åœ¨ PAR çš„å¥ åŸºä¹‹ä½œã€‚å°†å±æ€§åˆ—è¡¨è½¬åŒ–ä¸ºå¥å­å–‚ç»™ CLIPï¼Œè®©é¢„è®­ç»ƒæ¨¡å‹â€œé›¶æ ·æœ¬â€æˆ–â€œå°‘æ ·æœ¬â€ä¹Ÿèƒ½è¯†åˆ«å±æ€§ã€‚ |
| **GAAP: Attribute-guided Prompt for Unsupervised Person Retrieval**<br>(IJCAI 2024) [\[PDF\]](https://www.ijcai.org/proceedings/2024/116) | [Link](https://github.com/Event-AHU/OpenPAR) | **(æ— ç›‘ç£)** è§£å†³æ— æ ‡æ³¨éš¾é¢˜ã€‚åˆ©ç”¨â€œå±æ€§è¯â€ç”Ÿæˆ Prompt é©±åŠ¨ CLIP äº§ç”Ÿä¼ªæ ‡ç­¾ã€‚**å¯ç¤º**ï¼šè¯æ˜äº†å±æ€§å¯ä»¥ä½œä¸ºè·¨æ¨¡æ€æ£€ç´¢çš„ä¸­é—´æ¡¥æ¢ã€‚ |

### 3. Hard Settings (Video / Occlusion / Attack)
> **è¶‹åŠ¿è§£è¯»**: è§£å†³çœŸå®è½åœ°åœºæ™¯ä¸­çš„â€œç¡¬éª¨å¤´â€ï¼šè§†é¢‘å¸§å†—ä½™ã€ä¸¥é‡é®æŒ¡å’Œå®‰å…¨å¯¹æŠ—ã€‚

| Paper Title & Venue | Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **Spatio-Temporal Side Tuning Pre-trained Foundation Models**<br>(IEEE TCSVT 2024) [\[PDF\]](https://arxiv.org/abs/2404.17929) | [Link](https://github.com/Event-AHU/OpenPAR) | **(è§†é¢‘é«˜æ•ˆ)** é’ˆå¯¹è§†é¢‘ PARï¼Œæå‡ºäº† Side-Tuning (ä¾§è¾¹å¾®è°ƒ)ã€‚ä¸è®­ç»ƒå¤§æ¨¡å‹ï¼Œåªè®­ç»ƒæ—è¾¹çš„å°ç½‘ç»œï¼Œæ˜¾å­˜å ç”¨æä½ï¼Œå·¥ç¨‹ä»·å€¼æé«˜ã€‚ |
| **Pedestrian Attribute Recognition via Hierarchical Cross-Modality HyperGraph**<br>(ArXiv 2025) [\[PDF\]](https://arxiv.org/abs/2509.22331) | - | **(é®æŒ¡å¤„ç†)** å¼•å…¥è¶…å›¾ (HyperGraph)ã€‚æ™®é€šå›¾åªèƒ½è¿ä¸¤ç‚¹ï¼Œè¶…å›¾èƒ½æŠŠï¼ˆå¤´ã€å¸½å­ã€çœ¼é•œï¼‰æ‰“åŒ…æˆä¸€ä¸ªè¶…è¾¹ï¼Œä¸“é—¨è§£å†³å¤šéƒ¨ä½åŒæ—¶é®æŒ¡çš„é—®é¢˜ã€‚ |
| **Adversarial Semantic and Label Perturbation Attack for PAR (ASL-PAR)**<br>(ArXiv 2025) [\[PDF\]](https://arxiv.org/abs/2505.23313) | [Link](https://github.com/Event-AHU/OpenPAR) | **(å®‰å…¨æ”»é˜²)** PAR é¢†åŸŸçš„é¦–ä¸ªå¯¹æŠ—æ”»å‡»æ¡†æ¶ã€‚å¯¹äºç ”ç©¶æ¨¡å‹é²æ£’æ€§å’Œå®‰å…¨æ€§çš„åŒå­¦æ˜¯å¿…è¯»çš„å¼€å±±ä¹‹ä½œã€‚ |

---

## ğŸŒ Part 2: Global SOTA Extensions (2022-2025)
*æ”¶å½• Event-AHU ä¹‹å¤–çš„é¡¶ä¼š (CVPR, TPAMI, AAAI) æ ¸å¿ƒå·¥ä½œï¼Œè¡¥å…¨è§†é‡ã€‚*

| Paper Title & Venue | Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **Label-Balanced Multi-Label Learning for PAR**<br>(TPAMI 2024) [\[Link\]](https://ieeexplore.ieee.org/document/10856608) | [Link](https://github.com/Purdue-Digital-Twin/LBL) | **(é•¿å°¾åˆ†å¸ƒ)** ä¸“é—¨è§£å†³å±æ€§ä¸å¹³è¡¡é—®é¢˜ï¼ˆå¦‚â€œæˆ´å¸½å­â€çš„äººå¾ˆå°‘ï¼‰ã€‚æå‡ºäº†åŸºäºé‡é‡‡æ ·çš„å¹³è¡¡ç­–ç•¥ï¼Œæ•°å­¦æ¨å¯¼ä¸¥è°¨ã€‚ |
| **PromptPAR: A Prompt-based Framework for PAR**<br>(CVPR 2024) | - | **(åŠ¨æ€Prompt)** ç›¸æ¯”äº Event-AHU çš„å›ºå®š Promptï¼Œè¿™ç¯‡å·¥ä½œå°è¯•æ ¹æ®å›¾ç‰‡å†…å®¹åŠ¨æ€ç”Ÿæˆ Promptï¼Œè¿›ä¸€æ­¥æå‡äº†æ³›åŒ–æ€§ã€‚ |
| **Rethinking of PAR: A Reliable Evaluation**<br>(IEEE TCSVT 2023) [\[PDF\]](https://arxiv.org/abs/2305.08386) | [Link](https://github.com/Event-AHU/OpenPAR) | **(è¯„ä¼°æ ‡å‡†)** å¿…è¯»ï¼æŒ‡å‡ºäº†ç°æœ‰æ•°æ®é›†åˆ·æ¦œçš„è™šé«˜ç°è±¡ï¼Œå¹¶æå‡ºäº† Zero-Shot å’Œ Cross-Domain çš„æ–°è¯„ä¼°åè®®ã€‚ |
| **Relation-Aware PAR with Graph Convolutional Networks**<br>(AAAI 2022) [\[PDF\]](https://arxiv.org/abs/2204.03852) | [Link](https://github.com/Event-AHU/OpenPAR) | **(å›¾ç½‘ç»œç»å…¸)** 2022å¹´çš„æ ‡æ†ä¹‹ä½œã€‚åˆ©ç”¨ GCN æŒ–æ˜å±æ€§å…±ç°å…³ç³»ï¼ˆå¦‚ï¼šé•¿å‘->å¥³æ€§ï¼‰ï¼Œæ˜¯åç»­æ‰€æœ‰ Graph ç±»å·¥ä½œçš„é¼»ç¥–ã€‚ |

---

## ğŸ› ï¸ How to Contribute (å¦‚ä½•è´¡çŒ®)

æ¬¢è¿æäº¤ Pull Request è¡¥å……æ›´å¤š 2025 å¹´çš„æ–°å·¥ä½œï¼
1. Fork æœ¬ä»“åº“ã€‚
2. å°†æ–°è®ºæ–‡æ·»åŠ åˆ°å¯¹åº”çš„è¡¨æ ¼åˆ†ç±»ä¸­ã€‚
3. æäº¤ PRã€‚
## ğŸ“š ç»å…¸èµ„æºå›æº¯ (Before 2022)
å¦‚æœä½ éœ€è¦æŸ¥æ‰¾ 2022 å¹´ä»¥å‰çš„ç»å…¸ Baselineï¼Œè¯·å‚è€ƒï¼š
* [Older Works Collection 1](https://github.com/wangxiao5791509/Pedestrian-Attribute-Recognition-Paper-List)

