# ğŸŒŸ OpenPAR: The Ultimate Collection (2022-2025)

æœ¬é¡¹ç›®æ—¨åœ¨å»ºç«‹ä¸€ä¸ª **Pedestrian Attribute Recognition (PAR)** é¢†åŸŸçš„å…¨æ™¯çŸ¥è¯†åº“ã€‚
æ ¸å¿ƒå†…å®¹åŸºäº **Event-AHU (å®‰å¾½å¤§å­¦)** å›¢é˜Ÿçš„å¼€æºæˆæœï¼ŒåŒæ—¶æ”¶å½•äº† **CVPR / AAAI / TPAMI** ç­‰é¡¶çº§ä¼šè®®çš„ SOTA å·¥ä½œã€‚

> **ğŸš€ Core Framework**: [https://github.com/Event-AHU/OpenPAR](https://github.com/Event-AHU/OpenPAR)

---

## ğŸ”¥ Part 1: Event-AHU Core Works (2024-2025)
*åŸºäº OpenPAR æ¡†æ¶çš„æœ€æ–°å‰æ²¿è¿›å±•ï¼Œæ¶µç›– Mambaã€RWKVã€LLM åŠå¤æ‚åœºæ™¯ã€‚*

### 1. New Architectures (Mamba / RWKV / SNN)
> **è¶‹åŠ¿è§£è¯»**: æŠ›å¼ƒæ²‰é‡çš„ Transformerï¼Œè½¬å‘çº¿æ€§å¤æ‚åº¦çš„ Mamba å’Œ RWKVï¼Œè¿½æ±‚æè‡´çš„æ¨ç†æ•ˆç‡ã€‚

| Paper Title & Venue | Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **RGB-Event based PAR: Benchmark & Asymmetric RWKV Fusion**<br>(ArXiv 2025) [\[PDF\]](https://arxiv.org/abs/2504.10018) | [Link](https://github.com/Event-AHU/OpenPAR) | **(æœ€æ–°)** é¦–æ¬¡å¼•å…¥äº‹ä»¶ç›¸æœºè§£å†³å¤œé—´/è¿åŠ¨æ¨¡ç³Šéš¾é¢˜ã€‚**äº®ç‚¹**ï¼šè®¾è®¡äº†â€œéå¯¹ç§° RWKVâ€æ¶æ„ï¼Œä¸“é—¨å¤„ç†é«˜é¢‘ç¨€ç–çš„äº‹ä»¶æµæ•°æ®ï¼Œæ¯”çº¯ RGB æ–¹æ³•åœ¨å¤œé—´æå‡æ˜¾è‘—ã€‚ |
| **An Empirical Study of Mamba-based PAR**<br>(IEEE T-MM 2024) [\[PDF\]](https://arxiv.org/abs/2407.10374) | [Link](https://github.com/Event-AHU/OpenPAR) | **(åŸºå‡†)** PAR é¢†åŸŸé¦–ç¯‡ Mamba è¯„æµ‹ã€‚**é¿å‘**ï¼šå®éªŒå‘ç°ç›´æ¥å°†å±æ€§æ ‡ç­¾ä½œä¸º Token æ‹¼æ¥åˆ° VMamba ä¸­å¹¶ä¸èƒ½æå‡æ€§èƒ½ï¼Œè¿™æ‰“ç ´äº† ViT æ—¶ä»£çš„ç»éªŒä¸»ä¹‰ã€‚ |
| **SNN-PAR: Spiking Neural Networks for PAR**<br>(ICIG 2025) [\[PDF\]](https://arxiv.org/abs/2410.07857) | [Link](https://github.com/Event-AHU/OpenPAR) | **(ä½åŠŸè€—)** æ¢ç´¢è„‰å†²ç¥ç»ç½‘ç»œ (SNN) åœ¨ PAR ä¸­çš„åº”ç”¨ã€‚é€‚åˆéƒ¨ç½²åœ¨å¯¹åŠŸè€—æå…¶æ•æ„Ÿçš„è¾¹ç¼˜ç›‘æ§è®¾å¤‡ä¸Šã€‚ |

### 2. LLM & Vision-Language (Prompt / CLIP)
> **è¶‹åŠ¿è§£è¯»**: åˆ©ç”¨å¤§æ¨¡å‹ (LLM) çš„çŸ¥è¯†åº“æ¥å¼¥è¡¥è§†è§‰ç‰¹å¾çš„ä¸è¶³ï¼Œè§£å†³â€œé•¿å°¾å±æ€§â€å’Œâ€œè¯­ä¹‰ç†è§£â€é—®é¢˜ã€‚

| Paper Title & Venue | Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **PAR: A New Benchmark Dataset (MSP60K) & LLM Augmented Framework**<br>(AAAI 2025) [\[PDF\]](https://arxiv.org/abs/2408.09720) | [Link](https://github.com/Event-AHU/OpenPAR) | **(é‡ç£…æ•°æ®)** å‘å¸ƒäº† MSP60K (6ä¸‡å¼ å›¾)ï¼Œæ˜¯ PA100K ä¹‹åæœ€å¤§çš„æ–°åŸºå‡†ã€‚**äº®ç‚¹**ï¼šä¸ä»…ç”¨ LLM å¢å¼ºè®­ç»ƒï¼Œè¿˜ç”¨ LLM æ¸…æ´—äº†æ•°æ®æ ‡ç­¾ï¼Œè§£å†³äº†æ—§æ•°æ®é›†æ ‡æ³¨æ··ä¹±çš„é—®é¢˜ã€‚ |
| **Pedestrian Attribute Recognition via CLIP based Prompt Vision-Language Fusion**<br>(IEEE TCSVT 2024) [\[PDF\]](https://arxiv.org/abs/2312.10692) | [Link](https://github.com/Event-AHU/OpenPAR) | **(ç»å…¸)** Prompt Tuning åœ¨ PAR çš„å¥ åŸºä¹‹ä½œã€‚å°†å±æ€§åˆ—è¡¨è½¬åŒ–ä¸ºå¥å­å–‚ç»™ CLIPï¼Œè®©é¢„è®­ç»ƒæ¨¡å‹â€œé›¶æ ·æœ¬â€æˆ–â€œå°‘æ ·æœ¬â€ä¹Ÿèƒ½è¯†åˆ«å±æ€§ã€‚ |
| **GAAP: Attribute-guided Prompt for Unsupervised Person Retrieval**<br>(IJCAI 2024) [\[PDF\]](https://www.ijcai.org/proceedings/2024/116) | [Link](https://github.com/Event-AHU/OpenPAR) | **(æ— ç›‘ç£)** è§£å†³æ— æ ‡æ³¨éš¾é¢˜ã€‚åˆ©ç”¨â€œå±æ€§è¯â€ç”Ÿæˆ Prompt é©±åŠ¨ CLIP äº§ç”Ÿä¼ªæ ‡ç­¾ã€‚**å¯ç¤º**ï¼šè¯æ˜äº†å±æ€§å¯ä»¥ä½œä¸ºè·¨æ¨¡æ€æ£€ç´¢çš„ä¸­é—´æ¡¥æ¢ã€‚ |

### 3. Hard Settings (Video / Occlusion / Attack)
> **è¶‹åŠ¿è§£è¯»**: è§£å†³çœŸå®è½åœ°åœºæ™¯ä¸­çš„â€œç¡¬éª¨å¤´â€ï¼šè§†é¢‘å¸§å†—ä½™ã€ä¸¥é‡é®æŒ¡å’Œå®‰å…¨å¯¹æŠ—ã€‚

| Paper Title & Venue | Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **Spatio-Temporal Side Tuning Pre-trained Foundation Models**<br>(IEEE TCSVT 2024) [\[PDF\]](https://arxiv.org/abs/2404.17929) | [Link](https://github.com/Event-AHU/OpenPAR) | **(è§†é¢‘é«˜æ•ˆ)** é’ˆå¯¹è§†é¢‘ PARï¼Œæå‡ºäº† Side-Tuning (ä¾§è¾¹å¾®è°ƒ)ã€‚ä¸è®­ç»ƒå¤§æ¨¡å‹ï¼Œåªè®­ç»ƒæ—è¾¹çš„å°ç½‘ç»œï¼Œæ˜¾å­˜å ç”¨æä½ï¼Œå·¥ç¨‹ä»·å€¼æé«˜ã€‚ |
| **Pedestrian Attribute Recognition via Hierarchical Cross-Modality HyperGraph**<br>(ArXiv 2025) [\[PDF\]](https://arxiv.org/abs/2509.22331) | - | **(é®æŒ¡å¤„ç†)** å¼•å…¥è¶…å›¾ (HyperGraph)ã€‚æ™®é€šå›¾åªèƒ½è¿ä¸¤ç‚¹ï¼Œè¶…å›¾èƒ½æŠŠï¼ˆå¤´ã€å¸½å­ã€çœ¼é•œï¼‰æ‰“åŒ…æˆä¸€ä¸ªè¶…è¾¹ï¼Œä¸“é—¨è§£å†³å¤šéƒ¨ä½åŒæ—¶é®æŒ¡çš„é—®é¢˜ã€‚ |
| **Adversarial Semantic and Label Perturbation Attack for PAR (ASL-PAR)**<br>(ArXiv 2025) [\[PDF\]](https://arxiv.org/abs/2505.23313) | [Link](https://github.com/Event-AHU/OpenPAR) | **(å®‰å…¨æ”»é˜²)** PAR é¢†åŸŸçš„é¦–ä¸ªå¯¹æŠ—æ”»å‡»æ¡†æ¶ã€‚å¯¹äºç ”ç©¶æ¨¡å‹é²æ£’æ€§å’Œå®‰å…¨æ€§çš„åŒå­¦æ˜¯å¿…è¯»çš„å¼€å±±ä¹‹ä½œã€‚ |

---

## ğŸŒ Part 2: Global SOTA Extensions (2022-2025)
*æ”¶å½• Event-AHU ä¹‹å¤–çš„é¡¶ä¼š (CVPR, TPAMI, AAAI) æ ¸å¿ƒå·¥ä½œï¼Œè¡¥å…¨è§†é‡ã€‚*

| Paper Title & Venue | Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **Label-Balanced Multi-Label Learning for PAR**<br>(TPAMI 2024) [\[Link\]](https://ieeexplore.ieee.org/document/10856608) | [Link](https://github.com/Purdue-Digital-Twin/LBL) | **(é•¿å°¾åˆ†å¸ƒ)** ä¸“é—¨è§£å†³å±æ€§ä¸å¹³è¡¡é—®é¢˜ï¼ˆå¦‚â€œæˆ´å¸½å­â€çš„äººå¾ˆå°‘ï¼‰ã€‚æå‡ºäº†åŸºäºé‡é‡‡æ ·çš„å¹³è¡¡ç­–ç•¥ï¼Œæ•°å­¦æ¨å¯¼ä¸¥è°¨ã€‚ |
| **PromptPAR: A Prompt-based Framework for PAR**<br>(CVPR 2024) | - | **(åŠ¨æ€Prompt)** ç›¸æ¯”äº Event-AHU çš„å›ºå®š Promptï¼Œè¿™ç¯‡å·¥ä½œå°è¯•æ ¹æ®å›¾ç‰‡å†…å®¹åŠ¨æ€ç”Ÿæˆ Promptï¼Œè¿›ä¸€æ­¥æå‡äº†æ³›åŒ–æ€§ã€‚ |
| **Rethinking of PAR: A Reliable Evaluation**<br>(IEEE TCSVT 2023) [\[PDF\]](https://arxiv.org/abs/2305.08386) | [Link](https://github.com/Event-AHU/OpenPAR) | **(è¯„ä¼°æ ‡å‡†)** å¿…è¯»ï¼æŒ‡å‡ºäº†ç°æœ‰æ•°æ®é›†åˆ·æ¦œçš„è™šé«˜ç°è±¡ï¼Œå¹¶æå‡ºäº† Zero-Shot å’Œ Cross-Domain çš„æ–°è¯„ä¼°åè®®ã€‚ |
| **Relation-Aware PAR with Graph Convolutional Networks**<br>(AAAI 2022) [\[PDF\]](https://arxiv.org/abs/2204.03852) | [Link](https://github.com/Event-AHU/OpenPAR) | **(å›¾ç½‘ç»œç»å…¸)** 2022å¹´çš„æ ‡æ†ä¹‹ä½œã€‚åˆ©ç”¨ GCN æŒ–æ˜å±æ€§å…±ç°å…³ç³»ï¼ˆå¦‚ï¼šé•¿å‘->å¥³æ€§ï¼‰ï¼Œæ˜¯åç»­æ‰€æœ‰ Graph ç±»å·¥ä½œçš„é¼»ç¥–ã€‚ |

---

## ğŸ—ºï¸ Roadmap & Relationships (è®ºæ–‡å…³ç³»å›¾è°±)

æŠ€æœ¯æ˜¯å¦‚ä½•ä» 2022 æ¼”å˜åˆ° 2025 çš„ï¼Ÿè¯·çœ‹ä¸‹å›¾ï¼š

```mermaid
graph TD
    subgraph "Phase 1: Foundations (2022-2023)"
        A[<b>Relation Modeling</b><br>GCN (AAAI'22)]
        B[<b>Vision Transformer</b><br>ViT Baseline]
    end

    subgraph "Phase 2: Semantic Expansion (2023-2024)"
        B --> C[<b>CLIP-Prompt Fusion</b><br>TCSVT'24 (Prompt Tuning)]
        C --> C1[<b>Video Side-Tuning</b><br>TCSVT'24 (Efficiency)]
        C --> C2[<b>Unsupervised GAAP</b><br>IJCAI'24 (Pseudo Label)]
    end

    subgraph "Phase 3: New Era (2025)"
        B --> D[<b>Mamba & RWKV</b><br>T-MM'24 (Linear Complexity)]
        D --> D1[<b>RGB-Event Fusion</b><br>ArXiv'25 (Multi-Modal)]
        
        C --> E[<b>LLM Agent</b><br>AAAI'25 (MSP60K Dataset)]
        
        A --> F[<b>HyperGraph</b><br>ArXiv'25 (Structure Learning)]
    end
    
    style D fill:#f9f,stroke:#333,stroke-width:2px
    style E fill:#bbf,stroke:#333,stroke-width:2px
    style D1 fill:#f96,stroke:#333,stroke-width:2px



## ğŸ“š ç»å…¸èµ„æºå›æº¯ (Before 2022)
å¦‚æœä½ éœ€è¦æŸ¥æ‰¾ 2022 å¹´ä»¥å‰çš„ç»å…¸ Baselineï¼Œè¯·å‚è€ƒï¼š
* [Older Works Collection 1](https://github.com/wangxiao5791509/Pedestrian-Attribute-Recognition-Paper-List)
## ğŸ¤ å¦‚ä½•è´¡çŒ®
1. åœ¨ `papers` æ–‡ä»¶å¤¹ä¸­æ·»åŠ  PDFï¼ˆå¯é€‰ï¼‰ã€‚
2. åœ¨ `README.md` è¡¨æ ¼ä¸­è¿½åŠ æ–°è®ºæ–‡ã€‚
3. å¦‚æœå¤ç°äº†ä»£ç ï¼Œè¯·é“¾æ¥åˆ° `code/` ç›®å½•ã€‚
