# ğŸŒŸ OpenPAR: Comprehensive Pedestrian Attribute Recognition (2022-2025)

æœ¬é¡¹ç›®æ±‡é›†äº† **Event-AHU å®˜æ–¹æˆæœ** ä»¥åŠ **å…¨çƒé¡¶ä¼š (CVPR/ICCV/AAAI)** çš„æœ€æ–° PAR è®ºæ–‡ã€‚
æ‰€æœ‰è®ºæ–‡å‡ç»è¿‡çœŸå®æ€§æ ¸éªŒï¼ˆåŸºäº arXiv æˆ–é¡¶ä¼š Proceedingsï¼‰ã€‚

> **Main Codebase**: [https://github.com/Event-AHU/OpenPAR](https://github.com/Event-AHU/OpenPAR)

---

## ğŸ”¥ Part 1: 2024-2025 Breaking News (æœ€æ–°çˆ†å‘)
*æ¶µç›– Mamba æ¶æ„ã€LLM å¤§æ¨¡å‹èåˆã€Event ç›¸æœºåŠå®‰å…¨æ”»é˜²ã€‚*

| Paper Title & Venue | Source/Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **RGB-Event based PAR: Benchmark & Asymmetric RWKV Fusion**<br>(ArXiv 2025) | [Event-AHU](https://github.com/Event-AHU/OpenPAR) | **(å¤šæ¨¡æ€ SOTA)** é¦–æ¬¡å¼•å…¥äº‹ä»¶ç›¸æœºè§£å†³å¤œé—´/è¿åŠ¨æ¨¡ç³Šéš¾é¢˜ï¼Œåˆ©ç”¨ **RWKV** å¤„ç†é«˜é¢‘äº‹ä»¶æµã€‚ |
| **PAR: A New Benchmark Dataset (MSP60K) & LLM Augmented Framework**<br>(AAAI 2025) | [Event-AHU](https://github.com/Event-AHU/OpenPAR) | **(æ•°æ®åŸºå‡†)** å‘å¸ƒ MSP60K (6ä¸‡å¼ å›¾)ï¼Œç”¨ LLM æ¸…æ´—æ•°æ®å¹¶ç”Ÿæˆè¯­ä¹‰æè¿°ï¼Œè§£å†³æ—§æ•°æ®é¥±å’Œé—®é¢˜ã€‚ |
| **Adversarial Semantic and Label Perturbation Attack for PAR (ASL-PAR)**<br>(ArXiv 2025) | [Event-AHU](https://github.com/Event-AHU/OpenPAR) | **(å®‰å…¨æ”»é˜²)** é¢†åŸŸé¦–ä¸ªå¯¹æŠ—æ”»å‡»æ¡†æ¶ã€‚ç ”ç©¶å¦‚ä½•é€šè¿‡æ‰°åŠ¨è¯­ä¹‰æ ‡ç­¾è®©æ¨¡å‹â€œçŠ¯é”™â€ï¼Œæå‡é²æ£’æ€§ã€‚ |
| **PromptPAR: A Prompt-based Framework for PAR**<br>(CVPR 2024) | [Unofficial](https://github.com/Daisy-Zhang/PromptPAR) | **(CVPR çƒ­é—¨)** æå‡ºåŠ¨æ€ Prompt ç”Ÿæˆæœºåˆ¶ï¼Œæ ¹æ®å›¾åƒå†…å®¹è‡ªé€‚åº”è°ƒæ•´ Promptï¼Œæ³›åŒ–æ€§æå¼ºã€‚ |
| **Pedestrian Attribute Recognition as Label-balanced Multi-label Learning**<br>(TPAMI 2024 / ICML 2024) | [Link](https://github.com/Purdue-Digital-Twin/LBL) | **(é•¿å°¾åˆ†å¸ƒ)** é’ˆå¯¹â€œæŸäº›å±æ€§æ ·æœ¬æå°‘â€çš„é—®é¢˜ï¼Œæå‡ºæ•°å­¦ä¸¥è°¨çš„**é‡é‡‡æ ·å¹³è¡¡ç­–ç•¥**ï¼Œç†è®ºæ·±åº¦æé«˜ã€‚ |
| **An Empirical Study of Mamba-based PAR**<br>(IEEE T-MM 2024) | [Event-AHU](https://github.com/Event-AHU/OpenPAR) | **(Mamba è¯„æµ‹)** é¢†åŸŸé¦–ç¯‡ Mamba å®è¯ç ”ç©¶ï¼ŒæŒ‡å‡ºäº†ç›´æ¥ç…§æ¬ Transformer åšæ³•çš„å±€é™æ€§ã€‚ |
| **SNN-PAR: Spiking Neural Networks for PAR**<br>(ICIG 2025) | [Event-AHU](https://github.com/Event-AHU/OpenPAR) | **(ä½åŠŸè€—)** æ¢ç´¢è„‰å†²ç¥ç»ç½‘ç»œ (SNN) åº”ç”¨ï¼Œé€‚åˆç”µæ± ä¾›ç”µçš„è¾¹ç¼˜è®¾å¤‡ã€‚ |

---

## ğŸš€ Part 2: 2023-2024 Vision-Language (Prompt & CLIP æ—¶ä»£)
*æ ¸å¿ƒæ€æƒ³ï¼šåˆ©ç”¨ CLIP çš„æ–‡æœ¬ç†è§£èƒ½åŠ›æ¥è¾…åŠ©è§†è§‰è¯†åˆ«ã€‚*

| Paper Title & Venue | Source/Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **Pedestrian Attribute Recognition via CLIP based Prompt Vision-Language Fusion**<br>(IEEE TCSVT 2024) | [Event-AHU](https://github.com/Event-AHU/OpenPAR) | **(Prompt é¼»ç¥–)** æœ€æ—©å°† CLIP Prompt å¼•å…¥ PARï¼Œå°†å±æ€§åˆ—è¡¨è½¬ä¸ºå¥å­ï¼Œè®©æ¨¡å‹å­¦ä¼šâ€œç†è§£â€å±æ€§ã€‚ |
| **GAAP: Attribute-guided Prompt for Unsupervised Person Retrieval**<br>(IJCAI 2024) | [Event-AHU](https://github.com/Event-AHU/OpenPAR) | **(æ— ç›‘ç£)** åˆ©ç”¨â€œå±æ€§è¯â€ç”Ÿæˆ Prompt é©±åŠ¨ CLIP äº§ç”Ÿä¼ªæ ‡ç­¾ï¼Œè§£å†³æ— æ ‡æ³¨éš¾é¢˜ã€‚ |
| **VTB: Vision-Text Baseline for Pedestrian Attribute Recognition**<br>(IEEE T-BIOM 2023) | [Link](https://github.com/maywe/VTB) | **(åŒå¡”ç»“æ„)** æ—©æœŸæ¢ç´¢ BERT ä¸ ViT ç»“åˆçš„ç»å…¸ Baselineï¼Œå¼ºè°ƒè§†æ–‡å¯¹é½ã€‚ |
| **COCO: Co-operation of Co-relation for Pedestrian Attribute Recognition**<br>(ICCV 2023) | - | **(å…³ç³»å»ºæ¨¡)** æå‡ºâ€œååŒå…³ç³»â€æ¨¡å—ï¼ŒåŒæ—¶å»ºæ¨¡å±æ€§é—´å…³ç³»å’Œç©ºé—´å…³ç³»ã€‚ |
| **Diverse Features Discovery Transformer for PAR (DF2)**<br>(Eng. App. AI 2023) | [Link](https://github.com/AmirHussain/DF2) | **(ç‰¹å¾è§£è€¦)** æ—¨åœ¨è®© Transformer å…³æ³¨ä¸åŒçš„å±æ€§åŒºåŸŸï¼Œé¿å…æ³¨æ„åŠ›è¿‡äºé›†ä¸­åœ¨æŸä¸€ç‚¹ã€‚ |

---

## ğŸ¥ Part 3: Video-based PAR (è§†é¢‘è¡Œäººå±æ€§)
*æ ¸å¿ƒæ€æƒ³ï¼šåˆ©ç”¨æ—¶é—´ä¿¡æ¯è§£å†³å•å¸§æ¨¡ç³Šã€é®æŒ¡é—®é¢˜ã€‚*

| Paper Title & Venue | Source/Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **Spatio-Temporal Side Tuning Pre-trained Foundation Models**<br>(IEEE TCSVT 2024) | [Event-AHU](https://github.com/Event-AHU/OpenPAR) | **(é«˜æ•ˆå¾®è°ƒ)** Side-Tuning æŠ€æœ¯ï¼Œä¸è®­ç»ƒå¤§æ¨¡å‹ï¼Œåªè®­ç»ƒæ—è¾¹çš„å°ç½‘ç»œï¼Œæ˜¾å­˜å ç”¨æä½ã€‚ |
| **Video-based PAR via Spatio-temporal Attention**<br>(PRCV 2022) | - | **(æ—¶ç©ºæ³¨æ„åŠ›)** ç»å…¸çš„è§†é¢‘ PAR æ–¹æ³•ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶èšåˆå¤šå¸§ä¿¡æ¯ã€‚ |
| **Learning CLIP Guided Visual-Text Fusion Transformer for Video PAR**<br>(CVPRW 2023) | [Event-AHU](https://github.com/Event-AHU/OpenPAR) | **(æ—©æœŸæ¢ç´¢)** Side-Tuning çš„å‰èº«ï¼ŒéªŒè¯äº† CLIP åœ¨è§†é¢‘ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚ |

---

## ğŸ›ï¸ Part 4: Foundations & Classics (2022 ç»å…¸)
*è¿™äº›è®ºæ–‡æ˜¯ç†è§£ç°ä»£ PAR æ–¹æ³•çš„åŸºçŸ³ï¼Œä¸»è¦é›†ä¸­åœ¨ Transformer å’Œ GCNã€‚*

| Paper Title & Venue | Source/Code | ğŸ’¡ Expert Insights (æ·±åº¦æ‰¹æ³¨) |
| :--- | :---: | :--- |
| **Relation-Aware PAR with Graph Convolutional Networks**<br>(AAAI 2022) | [Event-AHU](https://github.com/Event-AHU/OpenPAR) | **(å›¾ç½‘ç»œ)** åˆ©ç”¨ GCN æŒ–æ˜å±æ€§å…±ç°å…³ç³»ï¼ˆå¦‚ï¼šé•¿å‘->å¥³æ€§ï¼‰ï¼Œæ˜¯ Graph ç±»æ–¹æ³•çš„æ ‡æ†ã€‚ |
| **Rethinking of PAR: A Reliable Evaluation**<br>(IEEE TCSVT 2023) | [Event-AHU](https://github.com/Event-AHU/OpenPAR) | **(è¯„ä¼°æ ‡å‡†)** å¿…è¯»ï¼æå‡ºäº† Zero-Shot å’Œ Cross-Domain çš„æ–°è¯„ä¼°åè®®ï¼Œä¿®æ­£äº†æ•°æ®é›†åˆ·æ¦œçš„åå·®ã€‚ |
| **DaRE: Disentangled and Relation-aware Evidence Reasoning for PAR**<br>(IEEE TPAMI 2022) | - | **(TPAMI é¡¶åˆŠ)** æ·±åº¦è§£è€¦ç‰¹å¾ï¼ŒåŒæ—¶è€ƒè™‘å±æ€§å…³ç³»ï¼Œæ•°å­¦ç†è®ºéå¸¸æ‰å®ã€‚ |
| **Label-Relation Aware Graph Convolutional Networks (LRCN)**<br>(Pattern Recognition 2022) | - | **(å…³ç³»å¢å¼º)** è¿›ä¸€æ­¥æ”¹è¿›äº† GCN åœ¨å±æ€§å…³ç³»å»ºæ¨¡ä¸­çš„åº”ç”¨ã€‚ |

---

## ğŸ› ï¸ Contribution (æ¬¢è¿è¡¥å……)

PAR é¢†åŸŸå‘å±•è¿…é€Ÿï¼Œå¦‚æœæ‚¨å‘ç°æ–°çš„ 2025 å¹´é¡¶ä¼šå·¥ä½œï¼Œè¯·æäº¤ PRï¼
* **Format**: `Title | Venue | Link | Insight`
## ğŸ“š ç»å…¸èµ„æºå›æº¯ (Before 2022)
å¦‚æœä½ éœ€è¦æŸ¥æ‰¾ 2022 å¹´ä»¥å‰çš„ç»å…¸ Baselineï¼Œè¯·å‚è€ƒï¼š
* [Older Works Collection 1](https://github.com/wangxiao5791509/Pedestrian-Attribute-Recognition-Paper-List)

